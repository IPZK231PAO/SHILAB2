# -*- coding: utf-8 -*-
"""LR_2_task_4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k9nsYR-p96TZrk5FBWKov_jIVeeR1AYD
"""

# Імпорт необхідних бібліотек
import numpy as np
import pandas as pd
from sklearn import preprocessing
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.metrics import accuracy_score, classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
import matplotlib.pyplot as plt

# Завантаження даних
input_file = 'income_data.txt'
data = pd.read_csv(input_file, header=None)

# Додавання назв стовпців (якщо їх немає)
data.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',
                'marital-status', 'occupation', 'relationship', 'race',
                'sex', 'capital-gain', 'capital-loss', 'hours-per-week',
                'native-country', 'income']

# Очищення даних
data = data.replace(' ?', np.nan).dropna()  # Видалення рядків з пропусками

# Перетворення категоріальних змінних
X = data.drop('income', axis=1)  # Вибір всіх стовпців, крім 'income'
y = data['income'].apply(lambda x: 1 if x == ' >50K' else 0)  # Бінаризація цільової змінної

# Перетворення категоріальних змінних в dummy-перемінні
X = pd.get_dummies(X, drop_first=True)

# Розділення на навчальну та тестову вибірки
X_train, X_validation, Y_train, Y_validation = train_test_split(X, y, test_size=0.20, random_state=1)

# Визначення моделей для порівняння
models = [
    ('LR', LogisticRegression(solver='liblinear')),
    ('LDA', LinearDiscriminantAnalysis()),
    ('KNN', KNeighborsClassifier()),
    ('CART', DecisionTreeClassifier()),
    ('NB', GaussianNB()),
    ('SVM', SVC(gamma='auto'))
]

# Оцінка моделей за допомогою перехресної валідації
results = []
names = []

for name, model in models:
    kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)
    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')
    results.append(cv_results)
    names.append(name)
    print(f'{name}: {cv_results.mean():.4f} ({cv_results.std():.4f})')

# Візуалізація порівняння алгоритмів
plt.boxplot(results, labels=names)
plt.title('Algorithm Comparison')
plt.ylabel('Accuracy')
plt.show()

# Порівняння прогнозів для найкращої моделі на тестовій вибірці
best_model = max(zip(names, results), key=lambda x: x[1].mean())[0]
print(f"Найкраща модель для цього завдання: {best_model}")